####################################### Klasyczne algorytmy uczenia maszynowego ########################################
from keras.datasets import mnist
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape(x_train.shape[0], -1) / 255.
x_test = x_test.reshape(x_test.shape[0], -1) / 255.

x_test = x_test[:1000, :]
y_test = y_test[:1000]

plt.imshow(x_train[0].reshape((28, 28)), cmap='gray')
plt.show()


knn = KNeighborsClassifier()
knn.fit(x_train, y_train)
predicted_classes = knn.predict(x_test)
print(accuracy_score(y_test, predicted_classes))

# Cwiczenie 5.1
from keras.datasets import mnist
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape(x_train.shape[0], -1) / 255.
x_test = x_test.reshape(x_test.shape[0], -1) / 255.

plt.imshow(x_train[0].reshape((28, 28)), cmap='gray')
plt.show()

X = x_train[:2000]
y = y_train[:2000]
knn = KNeighborsClassifier()
print(cross_val_score(knn, X, y, cv=3))

# Cwiczenie 5.2
from keras.datasets import mnist
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape(x_train.shape[0], -1) / 255.
x_test = x_test.reshape(x_test.shape[0], -1) / 255.

X = x_train[:2000]
y = y_train[:2000]
dt = DecisionTreeClassifier()

parameters = {'max_depth': [4, 6, 8], 'min_samples_leaf': [1, 3, 5]}

clf = GridSearchCV(dt, parameters)
clf.fit(X, y)

print(clf.best_params_)
print(clf.best_score_)